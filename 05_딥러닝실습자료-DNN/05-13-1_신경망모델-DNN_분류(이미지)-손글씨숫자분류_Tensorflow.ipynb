{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iD0F6TFRN0Ri"
   },
   "source": [
    "## **손글씨 숫자 이미지 분류 - MNIST를 활용한 DNN 모델 만들기_by Tensorflow**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pnatXXrsW58"
   },
   "source": [
    "## 1.라이브러리 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7504,
     "status": "ok",
     "timestamp": 1723468473244,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "Nv23kid7NvF3",
    "outputId": "e4deb62d-90b3-416e-8dc1-3ffbf36b9c6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Omg51eZJPB5f"
   },
   "source": [
    "## 2.MNIST 데이터셋 가져오고 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGkx_RyRPUBQ"
   },
   "source": [
    "- Keras 에는 MNIST 데이터셋이 내장되어 있어서 tf.keras.datasets.mnist.load_data() 메소드로 로딩을 할 수 있습니다. Training set에 6만개, Test set에 1만개의 손글씨 숫자 데이터와 정답지 라벨 데이터가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1723468857741,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "4pUagOCxPMJd",
    "outputId": "16f6354a-a1cc-4929-c71c-a8cf949f4213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (60000, 28, 28)\n",
      "shape of y_train: (60000,)\n",
      "shape of x_test: (10000, 28, 28)\n",
      "shape of y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print('shape of x_train:', x_train.shape)\n",
    "print('shape of y_train:', y_train.shape)\n",
    "print('shape of x_test:', x_test.shape)\n",
    "print('shape of y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfDmYCU1Pkl7"
   },
   "source": [
    "- Training set의 0번째 이미지 데이터 배열(28 by 28 array)과 정답지 라벨 ('5'), 그리고 matplotlib 으로 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1723468860580,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "LcUvEYIlPruu",
    "outputId": "794b0b19-0bd2-45d4-a3a2-a6485bb73e58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "ok",
     "timestamp": 1723468864189,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "1JSTzbloP5Gb",
    "outputId": "59630df8-1eed-4dfb-f947-aa23e7899c3d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "plt.imshow(x_train[0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-jj_ENO0bNf"
   },
   "source": [
    "## 3.데이터 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTEbmQodQHzX"
   },
   "source": [
    "\n",
    "    - 형태 맞추기     \n",
    "Deep Neural Network 모델의 input으로 넣기 위해 (28 by 28) 2차원 배열 (2D array) 이미지를 (28 * 28 = 784) 의 옆으로 길게 펼친 데이터 형태로 변형(Reshape) 합니다(Flatten() 메소드를 사용해도 됨).\n",
    "    - 정규화하기      \n",
    "    신경망은 입력 데이터의 스케일에 민감하기 때문에, 이 값을 0과 1 사이의 범위로 조정하는 정규화 과정(0~255 사이의 값을 0~1 사이의 실수 값으로 변환) 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZQ-XX0qFQMX-"
   },
   "outputs": [],
   "source": [
    "# reshape and normalization\n",
    "x_train = x_train.reshape((60000, 28 * 28)) / 255.0\n",
    "x_test = x_test.reshape((10000, 28 * 28)) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwEWv3T4QV7q"
   },
   "source": [
    "## 4.모델 구현하기\n",
    "- Keras의 핵심 데이터 구조로 모델(Models)과 층(Layers)이 있습니다.\n",
    "    - 모델 구축 두가지 방법\n",
    "        - (a) 순차적으로 층을 쌓아가는 Sequential model 과,\n",
    "        - (b) 복잡한 구조의 모델을 만들 때 사용하는 Keras functional API\n",
    "- 이미지 데이터 분류는 CNN (Convolutional Neural Network) 을 사용하면 효과적이나 이 예제에서는 간단하게 Sequential model 을 사용하여 모델 구성합니다.\n",
    " - (1)에서 전처리한 Input 이미지 데이터를 받아서, 1개의 완전히 연결된 은닉층 (Fully Connected Hidden Layer) 을 쌓고,\n",
    " - 10개의 classes 별 확률을 반환하는 FC(Fully Connected) Output Layer 를 쌓아서 만든 DNN(Deep Neural Network) 모델을 만들어보겠습니다.(Functional API 는 PyTorch 와 유사함)  \n",
    " - add() 메소드를 사용하면 마치 레고 블록을 쌓듯이 차곡차곡 순서대로 원하는 층을 쌓아서 딥러닝 모델을 설계할 수 있습니다.\n",
    "\n",
    "- (Dense, CNN, RNN, Embedding 등 모두 가능). Dense() 층의 units 매개변수에는 층별 노드 개수를 지정해주며, 활성화 함수는 activation 매개변수에서 지정해줍니다. 은닉층에서는 'Relu' 활성화함수를, Output 층에는 10개 classes에 대한 확률을 반환하므로 'softmax' 활성화함수를 사용하였습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M63yGTXXt4hJ"
   },
   "source": [
    "### 1)모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rarR4EJpQv_f"
   },
   "outputs": [],
   "source": [
    "# Sequential model\n",
    "# model = tf.keras.models.Sequential()\n",
    "# # Stacking layers\n",
    "# input_shape = (28*28,)\n",
    "# model.add(tf.keras.layers.Dense(128, activation='relu', input_shape=input_shape))\n",
    "# model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28*28,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFWN-Ko2Q5m-"
   },
   "source": [
    "- 층을 쌓아서 만든 DNN (Deep Neural Network) 모델이 어떻게 생겼는지 summary() 함수로 출력해보고, tf.keras.utils.plot_model() 메소드로 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1723468870816,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "OIjEAm_RRAUJ",
    "outputId": "2f2f1f3b-07ca-420b-db35-9984338190a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOtB9e0hREEO"
   },
   "source": [
    "### 2)모델 컴파일 (Compiling the model)하기\n",
    "-  기계가 이 모델을 이해할 수 있고 학습 절차를 설정할 수 있도록 컴파일(Compile) 해줍니다. compile() 메소드에는 딥러닝 학습 시 사용하는 (a) 오차 역전파 경사하강법 시 최적화 알고리즘(optimizer), (b) 손실함수(loss function), 그리고 (c) 성과평가 지표(metrics) 를 설정해줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Vio7-lW_RSMl"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True),\n",
    "#     loss=keras.losses.sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-ufQNEPRgWQ"
   },
   "source": [
    " - input data의 다수 클래스에 대한 정답 레이블(ground-truth labels)을 바로 사용하여 손실함수를 계산할 때는 loss='sparse_categorical_crossentropy' 을 사용\n",
    " - One-hot encoding 형태로 정답 레이블이 되어있다면 loss='categorical_crossentropy' 를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKDAjkPdR6Jt"
   },
   "source": [
    "###  3)모델 학습 (Training the model)\n",
    "\n",
    "- 데이터 준비와 모델 구축, 그리고 모델 컴파일이 끝났으므로 이제 6만개의 훈련 데이터셋(Training set) 중에서 80% (4.8만개 데이터) 는 모델 학습(fitting)에, 20%(1.2만개 데이터)는 검증(validation)용으로 사용하여 DNN 모델을 학습해보겠습니다. (참고로, 1만개의 Test set은 모델 학습에서는 사용하지 않으며, 최종 모델에 대해서 제일 마지막에 모델 성능 평가를 위해서만 사용합니다.)\n",
    "- epochs = 5 는 전체 데이터를 5번 반복(iteration)해서 사용해서 학습한다는 의미입니다.\n",
    "- verbose = 1 은 모델 학습 진행상황 막대를 출력하라는 의미입니다. ('1' 이 default이므로 생략 가능)(0 = silent, 1 = progress bar, 2 = one line per epoch)\n",
    "- validation_split=0.2 는 검증용 데이터셋을 별도로 만들어놓지 않았을 때 학습용 데이터셋에서 지정한 비율(예: 20%) 만큼을 분할하여 (hyperparameter tuning을 위한) 검증용 데이터셋으로 이용하라는 의미입니다.\n",
    "- batch_size=32 는 한번에 데이터 32개씩 batch로 가져다가 학습에 사용하라는 의미입니다.\n",
    "- 학습이 진행될수록 (즉, epochs 이 증가할 수록) 검증용 데이터셋에 대한 손실 값(loss value)은 낮아지고 정확도(accuracy)는 올라가고 있네요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43391,
     "status": "ok",
     "timestamp": 1723468914203,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "nFElphylST3e",
    "outputId": "e42e0a8d-f9f5-4adf-ee22-10be715ecf29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.7206 - accuracy: 0.8232 - val_loss: 0.3803 - val_accuracy: 0.8998\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3614 - accuracy: 0.9006 - val_loss: 0.3118 - val_accuracy: 0.9137\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3098 - accuracy: 0.9127 - val_loss: 0.2768 - val_accuracy: 0.9228\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2787 - accuracy: 0.9218 - val_loss: 0.2555 - val_accuracy: 0.9289\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2557 - accuracy: 0.9279 - val_loss: 0.2392 - val_accuracy: 0.9320\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2373 - accuracy: 0.9333 - val_loss: 0.2225 - val_accuracy: 0.9391\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2217 - accuracy: 0.9379 - val_loss: 0.2110 - val_accuracy: 0.9416\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.2083 - accuracy: 0.9409 - val_loss: 0.2012 - val_accuracy: 0.9442\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.1965 - accuracy: 0.9445 - val_loss: 0.1907 - val_accuracy: 0.9485\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.1858 - accuracy: 0.9472 - val_loss: 0.1833 - val_accuracy: 0.9501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22bbfd40520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HHVq7ZRSdcw"
   },
   "source": [
    "### 4)모델 평가 (Evaluating the model)\n",
    "= evaluate() 메소드를 사용하여 모델의 손실 값(Loss value) 과 컴파일 단계에서 추가로 설정해준 성능지표 값 (Metrics values) 을 Test set 에 대하여 평가할 수 있습니다. (다시 한번 강조하자면, Test set은 위의 (4)번 학습 단계에서 절대로 사용되어서는 안됩니다!)\n",
    "- Test set에 대한 cross entropy 손실값은 0.185, 정확도(accuracy)는 94.8% 가 나왔네요. (CNN 모델을 이용하고 hyperparameter tuning을 하면 99%까지 정확도를 올릴 수 있습니다.)\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1045,
     "status": "ok",
     "timestamp": 1723468915238,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "Vko90iZGS9el",
    "outputId": "0cb154c5-8c73-4886-bd6f-dd39e9e05b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.1812 - accuracy: 0.9491 - 465ms/epoch - 1ms/step\n",
      "test_loss: 0.18119074404239655\n",
      "test_accuracy: 0.9491000175476074\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss}\")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yK76ceIBTDi5"
   },
   "source": [
    "### 5)모델 예측하기 (Prediction for new data)\n",
    "위에서 학습한 DNN 모델을 사용해서 MNIST 이미지 데이터에 대해서 predict() 메소드를 사용하여 예측을 해보겠습니다. (별도의 새로운 데이터가 없으므로 test set 데이터를 사용함)굵은 텍스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1723468916544,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "zgJK4_UITPW1",
    "outputId": "4c7682aa-9f8c-409d-e842-114f8e88409a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 898us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.8839853e-05, 3.8318433e-07, 1.0742781e-03, 8.5337562e-03,\n",
       "       6.8086064e-07, 9.5851239e-05, 1.9117474e-08, 9.8991561e-01,\n",
       "       2.1357055e-05, 2.5930331e-04], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "# returns an array of probability per classes\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1723468916544,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "GG6VJbIcTQBA",
    "outputId": "32ba60ce-65d6-4e23-e635-8459aab123f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# position of max probability\n",
    "np.argmax(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1723468916544,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "bFyEbMbdTaov",
    "outputId": "27c2b3da-b73b-4abf-af34-423e8f04e74c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1308,
     "status": "ok",
     "timestamp": 1723468917849,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "0wbwnx5Nzqjf",
    "outputId": "dd737b3d-5d83-4329-d904-117788082a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n",
      "model.predict() 결과 :  [9.8839853e-05 3.8318433e-07 1.0742781e-03 8.5337562e-03 6.8086064e-07\n",
      " 9.5851239e-05 1.9117474e-08 9.8991561e-01 2.1357055e-05 2.5930331e-04]\n",
      "model이 추론한 가장 가능성이 높은 결과 :  7\n",
      "실제 데이터의 라벨 :  7\n"
     ]
    }
   ],
   "source": [
    "predicted_result = model.predict(x_test)  # model이 추론한 확률값.\n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "idx=0  #1번째 x_test를 살펴보자.\n",
    "print('model.predict() 결과 : ', predicted_result[idx])\n",
    "print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "print('실제 데이터의 라벨 : ', y_test[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1723469040566,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "-I7o2kwMzu-X",
    "outputId": "a6df8581-ac5f-4b5e-d78f-d171746931ab"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[idx].reshape(28, 28), cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9WbY4VjTe28"
   },
   "source": [
    "### 6)모델 저장, 불러오기 (Saving and Loading the model)\n",
    "- 딥러닝 모델의 성과 평가 결과 기준치를 충족하여 현장 적용이 가능한 경우라면 모델의 요소와 학습된 가중치 정보를 파일 형태로 저장하고, 배포, 로딩해서 (재)활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "iR-ToWL8ToQZ"
   },
   "outputs": [],
   "source": [
    "# Save the entire model to a HDF5 file.\n",
    "#model.save('mnist_dnn_model.h5')\n",
    "model.save('mnist_dnn_model.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KkAoW6vTtya"
   },
   "source": [
    "- 저장된 'mnist_dnn_model.h5' 모델/가중치 파일을 'new_model' 이름으로 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "executionInfo": {
     "elapsed": 378,
     "status": "ok",
     "timestamp": 1723469130575,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "45yJ6wsqTyKG",
    "outputId": "8eb6d501-2e29-432b-ecf2-39003b2ccddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "#new_model = tf.keras.models.load_model('mnist_dnn_model.h5')\n",
    "new_model = tf.keras.models.load_model('mnist_dnn_model.keras')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "## **2. 의류 이미지 분류 - Fashion MNIST를 활용한 DNN 모델 만들기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbVhjPpzn6BM"
   },
   "source": [
    "이 튜토리얼에서는 운동화나 셔츠 같은 옷 이미지를 분류하는 신경망 모델을 훈련합니다. 상세 내용을 모두 이해하지 못해도 괜찮습니다. 여기서는 완전한 텐서플로(TensorFlow) 프로그램을 빠르게 살펴 보겠습니다. 자세한 내용은 앞으로 배우면서 더 설명합니다.\n",
    "\n",
    "여기에서는 텐서플로 모델을 만들고 훈련할 수 있는 고수준 API인 [tf.keras](https://www.tensorflow.org/guide/keras)를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:03.209413Z",
     "iopub.status.busy": "2021-10-09T00:37:03.208893Z",
     "iopub.status.idle": "2021-10-09T00:37:04.729931Z",
     "shell.execute_reply": "2021-10-09T00:37:04.730297Z"
    },
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1723469136116,
     "user": {
      "displayName": "강희숙",
      "userId": "05520711596090317319"
     },
     "user_tz": -540
    },
    "id": "dzLKpmZICaWN",
    "outputId": "89339f75-5afb-4bf7-f720-39e638a455d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yR0EdgrLCaWR"
   },
   "source": [
    "## 1) 패션 MNIST 데이터셋 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLdCchMdCaWQ"
   },
   "source": [
    "10개의 범주(category)와 70,000개의 흑백 이미지로 구성된 [패션 MNIST](https://github.com/zalandoresearch/fashion-mnist) 데이터셋을 사용하겠습니다. 이미지는 해상도(28x28 픽셀)가 낮고 다음처럼 개별 옷 품목을 나타냅니다:\n",
    "\n",
    "<table>\n",
    "  <tr><td>     <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\" alt=\"Fashion MNIST sprite\" width=\"600\">   </td></tr>\n",
    "  <tr><td align=\"center\">     <b>그림 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">패션-MNIST 샘플</a> (Zalando, MIT License).<br>{nbsp}   </td></tr>\n",
    "</table>\n",
    "\n",
    "패션 MNIST는 컴퓨터 비전 분야의 \"Hello, World\" 프로그램격인 고전 [MNIST](http://yann.lecun.com/exdb/mnist/) 데이터셋을 대신해서 자주 사용됩니다. MNIST 데이터셋은 손글씨 숫자(0, 1, 2 등)의 이미지로 이루어져 있습니다. 여기서 사용하려는 옷 이미지와 동일한 포맷입니다.\n",
    "\n",
    "패션 MNIST는 일반적인 MNIST 보다 조금 더 어려운 문제이고 다양한 예제를 만들기 위해 선택했습니다. 두 데이터셋은 비교적 작기 때문에 알고리즘의 작동 여부를 확인하기 위해 사용되곤 합니다. 코드를 테스트하고 디버깅하는 용도로 좋습니다.\n",
    "\n",
    "여기에서 60,000개의 이미지를 사용하여 네트워크를 훈련하고 10,000개의 이미지를 사용하여 네트워크에서 이미지 분류를 학습한 정도를 평가합니다. TensorFlow에서 직접 Fashion MNIST에 액세스할 수 있습니다. TensorFlow에서 직접 [Fashion MNIST 데이터](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data)를 가져오고 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:04.734895Z",
     "iopub.status.busy": "2021-10-09T00:37:04.734362Z",
     "iopub.status.idle": "2021-10-09T00:37:05.637249Z",
     "shell.execute_reply": "2021-10-09T00:37:05.636740Z"
    },
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "...     # ... 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9FDsUlxCaWW"
   },
   "source": [
    "load_data() 함수를 호출하면 네 개의 넘파이(NumPy) 배열이 반환됩니다:\n",
    "\n",
    "- `train_images`와 `train_labels` 배열은 모델 학습에 사용되는 *훈련 세트*입니다.\n",
    "- `test_images`와 `test_labels` 배열은 모델 테스트에 사용되는 *테스트 세트*입니다.\n",
    "\n",
    "이미지는 28x28 크기의 넘파이 배열이고 픽셀 값은 0과 255 사이입니다. *레이블*(label)은 0에서 9까지의 정수 배열입니다. 이 값은 이미지에 있는 옷의 *클래스*(class)를 나타냅니다:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>레이블</th>\n",
    "    <th>클래스</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "각 이미지는 하나의 레이블에 매핑되어 있습니다. 데이터셋에 *클래스 이름*이 들어있지 않기 때문에 나중에 이미지를 출력할 때 사용하기 위해 별도의 변수를 만들어 저장합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.641741Z",
     "iopub.status.busy": "2021-10-09T00:37:05.641192Z",
     "iopub.status.idle": "2021-10-09T00:37:05.643058Z",
     "shell.execute_reply": "2021-10-09T00:37:05.642671Z"
    },
    "id": "IjnLH5S2CaWx"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Brm0b_KACaWX"
   },
   "source": [
    "## 2) 데이터 탐색\n",
    "\n",
    "모델을 훈련하기 전에 데이터셋 구조를 살펴보죠. 다음 코드는 훈련 세트에 60,000개의 이미지가 있다는 것을 보여줍니다. 각 이미지는 28x28 픽셀로 표현됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.648800Z",
     "iopub.status.busy": "2021-10-09T00:37:05.648200Z",
     "iopub.status.idle": "2021-10-09T00:37:05.650659Z",
     "shell.execute_reply": "2021-10-09T00:37:05.651008Z"
    },
    "id": "zW5k_xz1CaWX"
   },
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIAcvQqMCaWf"
   },
   "source": [
    "비슷하게 훈련 세트에는 60,000개의 레이블이 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.655028Z",
     "iopub.status.busy": "2021-10-09T00:37:05.654469Z",
     "iopub.status.idle": "2021-10-09T00:37:05.656993Z",
     "shell.execute_reply": "2021-10-09T00:37:05.657313Z"
    },
    "id": "TRFYHB2mCaWb"
   },
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSlYxFuRCaWk"
   },
   "source": [
    "각 레이블은 0과 9사이의 정수입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.661703Z",
     "iopub.status.busy": "2021-10-09T00:37:05.661122Z",
     "iopub.status.idle": "2021-10-09T00:37:05.664363Z",
     "shell.execute_reply": "2021-10-09T00:37:05.663970Z"
    },
    "id": "XKnCTHz4CaWg"
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMPI88iZpO2T"
   },
   "source": [
    "테스트 세트에는 10,000개의 이미지가 있습니다. 이 이미지도 28x28 픽셀로 표현됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.668323Z",
     "iopub.status.busy": "2021-10-09T00:37:05.667776Z",
     "iopub.status.idle": "2021-10-09T00:37:05.670735Z",
     "shell.execute_reply": "2021-10-09T00:37:05.671052Z"
    },
    "id": "2KFnYlcwCaWl"
   },
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd0A0Iu0CaWq"
   },
   "source": [
    "테스트 세트는 10,000개의 이미지에 대한 레이블을 가지고 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.675035Z",
     "iopub.status.busy": "2021-10-09T00:37:05.674468Z",
     "iopub.status.idle": "2021-10-09T00:37:05.677824Z",
     "shell.execute_reply": "2021-10-09T00:37:05.677397Z"
    },
    "id": "iJmPr5-ACaWn"
   },
   "outputs": [],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES6uQoLKCaWr"
   },
   "source": [
    "## 3) 데이터 전처리\n",
    "\n",
    "네트워크를 훈련하기 전에 데이터를 전처리해야 합니다. 훈련 세트에 있는 첫 번째 이미지를 보면 픽셀 값의 범위가 0~255 사이라는 것을 알 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.720032Z",
     "iopub.status.busy": "2021-10-09T00:37:05.693493Z",
     "iopub.status.idle": "2021-10-09T00:37:05.850523Z",
     "shell.execute_reply": "2021-10-09T00:37:05.850130Z"
    },
    "id": "m4VEw8Ud9Quh"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz7l27Lz9S1P"
   },
   "source": [
    "신경망 모델에 주입하기 전에 이 값의 범위를 0~1 사이로 조정하겠습니다. 이렇게 하려면 255로 나누어야 합니다. *훈련 세트*와 *테스트 세트*를 동일한 방식으로 전처리하는 것이 중요합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:05.854160Z",
     "iopub.status.busy": "2021-10-09T00:37:05.853630Z",
     "iopub.status.idle": "2021-10-09T00:37:05.998526Z",
     "shell.execute_reply": "2021-10-09T00:37:05.998008Z"
    },
    "id": "bW5WzIPlCaWv"
   },
   "outputs": [],
   "source": [
    "train_images = ...     # ... 코드 입력\n",
    "\n",
    "test_images = ...     # ... 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ee638AlnCaWz"
   },
   "source": [
    "*훈련 세트*에서 처음 25개 이미지와 그 아래 클래스 이름을 출력해 보죠. 데이터 포맷이 올바른지 확인하고 네트워크 구성과 훈련할 준비를 마칩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:06.077668Z",
     "iopub.status.busy": "2021-10-09T00:37:06.051526Z",
     "iopub.status.idle": "2021-10-09T00:37:06.852985Z",
     "shell.execute_reply": "2021-10-09T00:37:06.852546Z"
    },
    "id": "oZTImqg_CaW1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59veuiEZCaW4"
   },
   "source": [
    "## 4) 모델 구성\n",
    "\n",
    "신경망 모델을 만들려면 모델의 층을 구성한 다음 모델을 컴파일합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gxg1XGm0eOBy"
   },
   "source": [
    "### 4-1)층 설정\n",
    "\n",
    "신경망의 기본 빌딩 블록은 [*레이어*](https://www.tensorflow.org/api_docs/python/tf/keras/layers) 입니다. 레이어는 레이어에 공급된 데이터로부터 표현을 추출합니다. 이러한 표현은 당면한 문제에 의미가 있어야 합니다.\n",
    "\n",
    "대부분 딥러닝은 간단한 층을 연결하여 구성됩니다. `tf.keras.layers.Dense`와 같은 층들의 가중치(parameter)는 훈련하는 동안 학습됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:06.858821Z",
     "iopub.status.busy": "2021-10-09T00:37:06.857327Z",
     "iopub.status.idle": "2021-10-09T00:37:08.396243Z",
     "shell.execute_reply": "2021-10-09T00:37:08.396719Z"
    },
    "id": "9ODch-OFCaW4"
   },
   "outputs": [],
   "source": [
    "# 1개의 은닉층 - 노드 128 개 인 모델을 구성하세요\n",
    "model =  ...    # ... 코드 입력\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gut8A_7rCaW6"
   },
   "source": [
    "이 네트워크의 첫 번째 층인 `tf.keras.layers.Flatten`은 2차원 배열(28 x 28 픽셀)의 이미지 포맷을 28 * 28 = 784 픽셀의 1차원 배열로 변환합니다. 이 층은 이미지에 있는 픽셀의 행을 펼쳐서 일렬로 늘립니다. 이 층에는 학습되는 가중치가 없고 데이터를 변환하기만 합니다.\n",
    "\n",
    "픽셀을 펼친 후에는 두 개의 `tf.keras.layers.Dense` 층이 연속되어 연결됩니다. 이 층을 밀집 연결(densely-connected) 또는 완전 연결(fully-connected) 층이라고 부릅니다. 첫 번째 `Dense` 층은 128개의 노드(또는 뉴런)를 가집니다. 두 번째 (마지막) 층은 10개의 노드의 *소프트맥스*(softmax) 층입니다. 이 층은 10개의 확률을 반환하고 반환된 값의 전체 합은 1입니다. 각 노드는 현재 이미지가 10개 클래스 중 하나에 속할 확률을 출력합니다.\n",
    "\n",
    "### 4-2)모델 컴파일\n",
    "\n",
    "모델을 훈련할 준비가 되기 전에 몇 가지 설정이 더 필요합니다. 다음은 모델의 [*컴파일*](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) 단계에서 추가됩니다.\n",
    "\n",
    "- [*손실 함수*](https://www.tensorflow.org/api_docs/python/tf/keras/losses) - 훈련 중 모델이 얼마나 정확한지 측정합니다. 모델을 올바른 방향으로 \"조정\"하려면 이 함수를 최소화해야 합니다.\n",
    "- [*옵티마이저*](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) - 모델이 인식하는 데이터와 해당 손실 함수를 기반으로 모델이 업데이트되는 방식입니다.\n",
    "- [*메트릭*](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) — 훈련 및 테스트 단계를 모니터링하는 데 사용됩니다. 다음 예에서는 올바르게 분류된 이미지의 비율인 *정확도*를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:08.405187Z",
     "iopub.status.busy": "2021-10-09T00:37:08.404649Z",
     "iopub.status.idle": "2021-10-09T00:37:08.412602Z",
     "shell.execute_reply": "2021-10-09T00:37:08.412174Z"
    },
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": [
    "# 모델 컴파일하기 : 손실함수 - 'sparse_categorical_crossentropy', 옵티마이저 : 'adam' , metricsc : 'accuracy'\n",
    "\n",
    "...    # ... 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "## 5) 모델 훈련\n",
    "\n",
    "신경망 모델을 훈련하려면 다음 단계가 필요합니다.\n",
    "\n",
    "1. 훈련 데이터를 모델에 주입합니다-이 예에서는 `train_images`와 `train_labels` 배열입니다.\n",
    "2. 모델이 이미지와 레이블을 매핑하는 방법을 배웁니다.\n",
    "3. 테스트 세트에 대한 모델의 예측을 만듭니다-이 예에서는 `test_images` 배열입니다. 이 예측이 `test_labels` 배열의 레이블과 맞는지 확인합니다.\n",
    "4. 예측이 `test_labels` 배열의 레이블과 일치하는지 확인합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4P4zIV7E28Z"
   },
   "source": [
    "- 모델 학습\n",
    "\n",
    "훈련을 시작하려면 [`model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) 메서드를 호출합니다. 모델을 훈련 데이터에 \"맞추기(fit)\" 때문에 이렇게 불립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:08.416634Z",
     "iopub.status.busy": "2021-10-09T00:37:08.416057Z",
     "iopub.status.idle": "2021-10-09T00:37:35.643885Z",
     "shell.execute_reply": "2021-10-09T00:37:35.644240Z"
    },
    "id": "xvwvpA64CaW_"
   },
   "outputs": [],
   "source": [
    "# 모델 학습하기  - epochs = 10\n",
    "history = ...     # ... 코드 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rn3dfNvxmbu5"
   },
   "source": [
    "## 6) 모델 훈련 후 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0u35pqiHmb8c"
   },
   "outputs": [],
   "source": [
    "# 모델 학습과정 그래프로 나타내기\n",
    "\n",
    "...     # ... 코드 입력\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3ZVOhugCaXA"
   },
   "source": [
    "모델이 훈련되면서 손실과 정확도 지표가 출력됩니다. 이 모델은 훈련 세트에서 약 0.88(88%) 정도의 정확도를 달성합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCpr6DGyE28h"
   },
   "source": [
    "## 7) 모델 평가\n",
    "\n",
    "모델이 테스트 데이터세트에서 작동하는 방식을 비교합니다. - evaluate() 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:35.648923Z",
     "iopub.status.busy": "2021-10-09T00:37:35.648296Z",
     "iopub.status.idle": "2021-10-09T00:37:36.162471Z",
     "shell.execute_reply": "2021-10-09T00:37:36.162831Z"
    },
    "id": "VflXLEeECaXC"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = ...     # ... 코드 입력\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWfgsmVXCaXG"
   },
   "source": [
    "테스트 세트의 정확도가 훈련 세트의 정확도보다 조금 낮습니다. 훈련 세트의 정확도와 테스트 세트의 정확도 사이의 차이는 *과대적합*(overfitting) 때문입니다. 과대적합은 머신러닝 모델이 훈련 데이터보다 새로운 데이터에서 성능이 낮아지는 현상을 말합니다.\n",
    "\n",
    "- [과대적합 시연](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#demonstrate_overfitting)\n",
    "- [과대적합을 방지하기 위한 전략](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-PyD1SYE28q"
   },
   "source": [
    "## 8) 예측하기\n",
    "\n",
    "훈련된 모델을 사용하여 일부 이미지에 대한 예측을 수행할 수 있습니다. 모델의 선형 출력, [로짓](https://developers.google.com/machine-learning/glossary#logits). 소프트맥스 레이어를 연결하여 로짓을 해석하기 쉬운 확률로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.167730Z",
     "iopub.status.busy": "2021-10-09T00:37:36.167212Z",
     "iopub.status.idle": "2021-10-09T00:37:36.180366Z",
     "shell.execute_reply": "2021-10-09T00:37:36.179971Z"
    },
    "id": "DnfNA0CrQLSD"
   },
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model,\n",
    "                                         tf.keras.layers.Softmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.183891Z",
     "iopub.status.busy": "2021-10-09T00:37:36.183346Z",
     "iopub.status.idle": "2021-10-09T00:37:36.517176Z",
     "shell.execute_reply": "2021-10-09T00:37:36.517584Z"
    },
    "id": "Gl91RPhdCaXI"
   },
   "outputs": [],
   "source": [
    "predictions = probability_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9Kk1voUCaXJ"
   },
   "source": [
    "여기서는 테스트 세트에 있는 각 이미지의 레이블을 예측했습니다. 첫 번째 예측을 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.522707Z",
     "iopub.status.busy": "2021-10-09T00:37:36.521976Z",
     "iopub.status.idle": "2021-10-09T00:37:36.524636Z",
     "shell.execute_reply": "2021-10-09T00:37:36.524984Z"
    },
    "id": "3DmJEUinCaXK"
   },
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hw1hgeSCaXN"
   },
   "source": [
    "이 예측은 10개의 숫자 배열로 나타납니다. 이 값은 10개의 옷 품목에 상응하는 모델의 신뢰도(confidence)를 나타냅니다. 가장 높은 신뢰도를 가진 레이블을 찾아보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.529353Z",
     "iopub.status.busy": "2021-10-09T00:37:36.528635Z",
     "iopub.status.idle": "2021-10-09T00:37:36.531474Z",
     "shell.execute_reply": "2021-10-09T00:37:36.530989Z"
    },
    "id": "qsqenuPnCaXO"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E51yS7iCCaXO"
   },
   "source": [
    "모델은 이 이미지가 앵클 부츠(`class_name[9]`)라고 가장 확신하고 있습니다. 이 값이 맞는지 테스트 레이블을 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.535822Z",
     "iopub.status.busy": "2021-10-09T00:37:36.535087Z",
     "iopub.status.idle": "2021-10-09T00:37:36.537594Z",
     "shell.execute_reply": "2021-10-09T00:37:36.537953Z"
    },
    "id": "Sd7Pgsu6CaXP"
   },
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygh2yYC972ne"
   },
   "source": [
    "10개 클래스에 대한 예측을 모두 그래프로 표현해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.544429Z",
     "iopub.status.busy": "2021-10-09T00:37:36.543805Z",
     "iopub.status.idle": "2021-10-09T00:37:36.546023Z",
     "shell.execute_reply": "2021-10-09T00:37:36.545602Z"
    },
    "id": "DvYmmrpIy6Y1"
   },
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  true_label, img = true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  true_label = true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh9yABaME29S"
   },
   "source": [
    "## 9) 예측 확인\n",
    "\n",
    "훈련된 모델을 사용하여 일부 이미지에 대한 예측을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Ov9OFDMmOD"
   },
   "source": [
    "0번째 원소의 이미지, 예측, 신뢰도 점수 배열을 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.566345Z",
     "iopub.status.busy": "2021-10-09T00:37:36.565751Z",
     "iopub.status.idle": "2021-10-09T00:37:36.658377Z",
     "shell.execute_reply": "2021-10-09T00:37:36.657973Z"
    },
    "id": "HV5jw-5HwSmO"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.678220Z",
     "iopub.status.busy": "2021-10-09T00:37:36.673370Z",
     "iopub.status.idle": "2021-10-09T00:37:36.768534Z",
     "shell.execute_reply": "2021-10-09T00:37:36.768941Z"
    },
    "id": "Ko-uzOufSCSe"
   },
   "outputs": [],
   "source": [
    "i = 12\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgdvGD52CaXR"
   },
   "source": [
    "몇 개의 이미지의 예측을 출력해 보죠. 올바르게 예측된 레이블은 파란색이고 잘못 예측된 레이블은 빨강색입니다. 숫자는 예측 레이블의 신뢰도 퍼센트(100점 만점)입니다. 신뢰도 점수가 높을 때도 잘못 예측할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:36.818460Z",
     "iopub.status.busy": "2021-10-09T00:37:36.803865Z",
     "iopub.status.idle": "2021-10-09T00:37:38.507593Z",
     "shell.execute_reply": "2021-10-09T00:37:38.507977Z"
    },
    "id": "hQlnbqaw2Qu_"
   },
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R32zteKHCaXT"
   },
   "source": [
    "## 10) 훈련된 모델 사용하기\n",
    "\n",
    "마지막으로 훈련된 모델을 사용하여 한 이미지에 대한 예측을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:38.512157Z",
     "iopub.status.busy": "2021-10-09T00:37:38.511582Z",
     "iopub.status.idle": "2021-10-09T00:37:38.513998Z",
     "shell.execute_reply": "2021-10-09T00:37:38.513554Z"
    },
    "id": "yRJ7JU7JCaXT"
   },
   "outputs": [],
   "source": [
    "# Grab an image from the test dataset.\n",
    "img = test_images[1]\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vz3bVp21CaXV"
   },
   "source": [
    "`tf.keras` 모델은 한 번에 샘플의 묶음 또는 *배치*(batch)로 예측을 만드는데 최적화되어 있습니다. 하나의 이미지를 사용할 때에도 2차원 배열로 만들어야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:38.517877Z",
     "iopub.status.busy": "2021-10-09T00:37:38.517310Z",
     "iopub.status.idle": "2021-10-09T00:37:38.519150Z",
     "shell.execute_reply": "2021-10-09T00:37:38.519501Z"
    },
    "id": "lDFh5yF_CaXW"
   },
   "outputs": [],
   "source": [
    "# Add the image to a batch where it's the only member.\n",
    "img = (np.expand_dims(img,0))\n",
    "\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ5wLTkcCaXY"
   },
   "source": [
    "이제 이 이미지의 예측을 만듭니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:38.523771Z",
     "iopub.status.busy": "2021-10-09T00:37:38.523232Z",
     "iopub.status.idle": "2021-10-09T00:37:38.556846Z",
     "shell.execute_reply": "2021-10-09T00:37:38.556341Z"
    },
    "id": "o_rzNSdrCaXY"
   },
   "outputs": [],
   "source": [
    "predictions_single = probability_model.predict(img)\n",
    "\n",
    "print(predictions_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:38.597375Z",
     "iopub.status.busy": "2021-10-09T00:37:38.596804Z",
     "iopub.status.idle": "2021-10-09T00:37:38.650107Z",
     "shell.execute_reply": "2021-10-09T00:37:38.649667Z"
    },
    "id": "6Ai-cpLjO-3A"
   },
   "outputs": [],
   "source": [
    "plot_value_array(1, predictions_single[0], test_labels)\n",
    "_ = plt.xticks(range(10), class_names, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU1Y2OAMCaXb"
   },
   "source": [
    "`tf.keras.Model.predict`는 데이터 배치의 각 이미지에 대해 하나의 목록씩 목록의 목록을 반환합니다. 배치에서 (유일한) 이미지에 대한 예측을 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-09T00:37:38.654503Z",
     "iopub.status.busy": "2021-10-09T00:37:38.653890Z",
     "iopub.status.idle": "2021-10-09T00:37:38.656449Z",
     "shell.execute_reply": "2021-10-09T00:37:38.656801Z"
    },
    "id": "2tRmdq_8CaXb"
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions_single[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFc2HbEVCaXd"
   },
   "source": [
    "예상과 같이 모델이 레이블을 예측합니다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pshgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
