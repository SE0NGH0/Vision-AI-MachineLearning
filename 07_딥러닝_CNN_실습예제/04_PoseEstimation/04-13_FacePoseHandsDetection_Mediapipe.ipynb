{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mideapipe를 사용하기 위한 가상환경 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda create -n mediapipe-env python=3.9 -y\n",
    "# conda activate mediapipe-env\n",
    "\n",
    "# pip install opencv-python mediapipe protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴 감지 기능\n",
    "- 얼굴 위치와 크기 탐지 (+ 코끝, 눈 위치 등 keypoint 일부) \n",
    "- mp_face_detection.FaceDetection(...)        \n",
    "https://www.pexels.com/ko-kr/video/3256542/  대화나누는 동영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmediapipe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 얼굴을 찾고, 찾은 얼굴에 표시를 해주기 위한 변수 정의\u001b[39;00m\n\u001b[0;32m      5\u001b[0m mp_face_detection \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39msolutions\u001b[38;5;241m.\u001b[39mface_detection \u001b[38;5;66;03m# 얼굴 검출을 위한 face_detection 모듈 사용\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# 얼굴을 찾고, 찾은 얼굴에 표시를 해주기 위한 변수 정의\n",
    "mp_face_detection = mp.solutions.face_detection # 얼굴 검출을 위한 face_detection 모듈 사용\n",
    "mp_drawing = mp.solutions.drawing_utils # 얼굴 특징을 그리기 위한 drawing_tuils 모듈 사용\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# FaceDetection 솔루션 초기화 (실시간 모드로 사용)\n",
    "with mp_face_detection.FaceDetection(\n",
    "    # 모델의 선택(model_selection)과 최소 감지 신뢰도(min_detection_confidence) 설정\n",
    "    model_selection=0, \n",
    "    min_detection_confidence=0.5\n",
    ") as face_detection:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: \n",
    "            break\n",
    "\n",
    "        # BGR → RGB로 변환 (MediaPipe는 RGB 이미지 필요)\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) \n",
    "        image.flags.writeable = False  # 성능 최적화 (읽기 전용)\n",
    "        \n",
    "        # 얼굴 감지 실행\n",
    "        results = face_detection.process(image)\n",
    "\n",
    "        image.flags.writeable = True  # 다시 쓰기 가능 상태로 변경\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        #  얼굴 감지 결과가 있을 경우 실행\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                mp_drawing.draw_detection(image, detection)\n",
    "                \n",
    "        # 결과 이미지 출력 (크기 축소)\n",
    "        cv2.imshow('MediaPipe Face Detection', cv2.resize(image, None , fx=0.5, fy=0.5))\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전신 포즈 추정\n",
    "- MediaPipe의 Pose 모듈은 사람의 전신 33개 주요 관절(keypoints)을 실시간으로 감지 : 자세 분석\n",
    "    - 얼굴: nose, eyes, ears\n",
    "    - 상체: shoulders, elbows, wrists\n",
    "    - 하체: hips, knees, ankles\n",
    "    - 발끝, 발뒤꿈치 등\n",
    "- mp_pose.Pose(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe의 pose 솔루션과 drawing 유틸리티 불러오기\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# pose 솔루션 초기화 (실시간 모드로 사용)\n",
    "with mp_pose.Pose(\n",
    "    static_image_mode=False,        # 동영상(실시간) 모드\n",
    "    model_complexity=1,             # 모델 복잡도 (0~2)\n",
    "    enable_segmentation=False,      # 사람 영역 분할 안 함\n",
    "    min_detection_confidence=0.5    # 최소 감지 신뢰도\n",
    ") as pose:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGR → RGB로 변환 (MediaPipe는 RGB 이미지 필요)\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False  # 성능 최적화 (읽기 전용)\n",
    "\n",
    "        # 포즈 추정 실행\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True  # 다시 쓰기 가능 상태로 변경\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 포즈 추정 결과가 있을 경우 랜드마크 그리기\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,                         # 원본 이미지\n",
    "                results.pose_landmarks,        # 감지된 포즈 랜드마크\n",
    "                mp_pose.POSE_CONNECTIONS       # 관절 연결선\n",
    "            )\n",
    "\n",
    "        # 결과 이미지 출력 (크기 축소)\n",
    "        cv2.imshow('MediaPipe Pose Detection', cv2.resize(image, None, fx=0.7, fy=0.7))\n",
    "        \n",
    "        # ESC 키(27번) 누르면 종료\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "# 웹캠과 윈도우 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MediaPipe Hands: 손 관절 21개 감지\n",
    "- 21개 손가락 관절 위치 추정(제스처 인식 등)\n",
    "- mp_hands.Hands(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe 손 추적 모듈과 그리기 유틸리티 불러오기\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 웹캠 켜기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 손 추적기 초기화\n",
    "with mp_hands.Hands(\n",
    "    max_num_hands=2,                   # 최대 추적 손 개수\n",
    "    min_detection_confidence=0.5,      # 감지 신뢰도\n",
    "    min_tracking_confidence=0.5        # 추적 신뢰도\n",
    ") as hands:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"카메라 프레임을 읽을 수 없습니다.\")\n",
    "            continue\n",
    "\n",
    "        # BGR → RGB 변환 (MediaPipe는 RGB 입력 필요)\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False  # 성능 향상을 위한 설정\n",
    "\n",
    "        # 손 감지 수행\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # 다시 BGR로 변환 후 쓰기 가능 상태로 전환\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 감지된 손이 있으면 각 손의 랜드마크를 그림\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, \n",
    "                    hand_landmarks, \n",
    "                    mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # 결과 출력\n",
    "        cv2.imshow('MediaPipe Hands', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(1) == ord('q') :  # ESC 키로 종료\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
